{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Data Analysis with Python\n",
    "In the last class, we introduced basic programming concepts such as different data types, conditional statements, and looping. Today, we will focus on working with tabular data and some common tasks you may want to do when working with data. To do this, we will be using additonal libraries on top of the base functionality that comes with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Pandas\n",
    "Since we installed Anaconda, we already have additional libraries for data analysis installed. The first one we will work with is called `Pandas` which is a useful library for reading in and working with data. If you did not already have Pandas installed, you could install it with the following command: `conda install pandas` or `pip install pandas` if you were using base Python. Once you have a library installed, you will still need to `import` it to use it in your script. We will import Pandas below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case anyone has trouble with importing pandas, uncomment the line below and run the cell\n",
    "# !conda install --yes pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas\n",
    "# the `as pd` allows us to pandas functions with a shortened name\n",
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and view data\n",
    "Now that we have `Pandas` imported, we can begin using it. For this workshop, we will be using data from a study on the ranges of pet cats in the UK and the US. A link to the study can be found [here](https://zslpublications.onlinelibrary.wiley.com/doi/10.1111/acv.12563) and the data can be downloaded [here](https://datarepository.movebank.org/search?query=Data%20from:%20The%20small%20home%20ranges%20and%20large%20local%20ecological%20impacts%20of%20pet%20cats). \n",
    "The first thing we will do is read in a csv file of this data with the `read_csv()` function. When we do this, it will store our data as a `DataFrame` object. Pandas DataFrames are 2D tabular data structures consisitng of rows and columns. DataFrames have built in methods to help manipulate them. We will learn more about those as we move through this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "# to call a function from the pandas library we will need to type pd.function_name\n",
    "\n",
    "# there is also a function for reading in excel files (pd.read_excel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've read in our data, we can begin investigating it. There are several useful methods for familarizing yourself with the information stored in a DataFrame. If you want to see a glimpse of your dataset, you can use the `.head()` method which returns the first 5 rows of your dataset. This can give you a sense of your columns and the types of information stored in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling head\n",
    "\n",
    "\n",
    "# if you want to see more rows of your dataset you can specify the number within the paranthesis\n",
    "\n",
    "\n",
    "# there is also a parallel function to .head() called .tail() which will return a snapshot of the last rows of your data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `.head()` is useful for viewing a snapshot of your data, it does not answer all the questions you may have about your dataset. For example, when working with data, it's important to keep track of how much data you have. You will want to know how many rows or observations you have and how many columns or attributes you have. This becomes particularly important when you begin manipulating your data because you may accidently remove or duplicate information. To find this information out, you can call `.shape`  which will return the number of rows and columns. Try it out below and see how many obersvations we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call .shape on cats_uk.\n",
    "\n",
    "\n",
    "# .shape is not followed by '()' because we are accessing an attribute instead of calling a method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a sense of how much data we have, but we still have not summarized the type of information stored in each column. To get a better summary of our entire dataset, we can use the `.describe()` and `.info()` methods. The `.describe()` method will generate summary statistics for numeric columns and the `.info()` method will provide a list of the columns, the data type of each column, and the number of non-null values. Keeping track of null values is important because it can affect your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call .describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call .info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try it for yourself. In the below code cell, read in the data file `Pet Cats United States.csv` into the variable cats_us. Then perform the following tasks/answer the questions.\n",
    "\n",
    "- Display the first 7 rows of the data\n",
    "- Display the last 7 rows of the data\n",
    "- What is the mean of the height-above-ellipsoid column?\n",
    "- Are there any null values in the visible column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "cats_us \n",
    "\n",
    "# display the first 7 rows\n",
    "\n",
    "\n",
    "# display the last 7 rows\n",
    "\n",
    "\n",
    "# mean of height-above-ellipsoid\n",
    "\n",
    "# mean is 37.032907\n",
    "\n",
    "# check for null values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating or deleting columns\n",
    "Once you have read in a dataset, you may want to create additional columns or delete columns that you don't need. To create a column, you can use bracket notation with the name of your new column as such `dataframe['new_column'] = some_value` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new column and setting the value to 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete columns, you use the `del` keyword. Let's delete the column we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting the column\n",
    "\n",
    "\n",
    "# how can we check the column was deleted (there are multiple)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing and filtering data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting columns\n",
    "Now that we've seen some general summaries of our data, we may want to focus on a specific column or attribute. To access a column in a DataFrame, you use the following formats `dataframe.column_name` or `dataframe['column_name']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the timestamp column\n",
    "\n",
    "# first with dictionary syntax\n",
    "\n",
    "\n",
    "# now with attribute syntax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to select multiple columns at the same time, you can provide the column names in a list like this `dataframe[['column_name1', 'column_name2']]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now select timestamp and visible\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to access columns is with the `.loc` and `.iloc` attributes. The `.loc()` attribute uses labels to select data and the `.iloc()` attribute uses indeces to select data. Both will be called in a similar way where bracket notation is used to select data. The calls will look something like this `dataframe.loc[row_name(s), column_name(s)]` or `dataframe.iloc[row_index, column_index]`. If you would like to select all rows or all columns, you can use the `:` symbol. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select timestamp with loc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you try:\n",
    "- create a new column in cats_uk called 'region' and set it equal to 'UK'\n",
    "- create a new column in cats_us called 'region' and set it eqaul to 'US'\n",
    "- select the timestamp column using .iloc()\n",
    "- select the first 11 rows and all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create region columns\n",
    "\n",
    "\n",
    "# select timestamp with iloc\n",
    "\n",
    "# select the first 11 rows and all columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing operations on columns\n",
    "Now that we now how to access a specific column, we can use other methods or functions to gain more information. For example, we may want to know how many unique values are in a column. This can be particularly useful if you have a text column or one that represents different groups within your data. In the cats dataset, the individual-local-identifier column represents the different cats we have data for. So far, we've only seen `Ares` within the individual-local-identifier column. Let's find out how many other cats are in the dataset. To do this, we will access the individual-local-identifier column and then use the `unique()` function to return a list of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing the Phrase column and then calling unique()\n",
    "\n",
    "# when we call multiple attributes or fucntions together this is called chaining\n",
    "\n",
    "# call len() to get the length of the array\n",
    "\n",
    "\n",
    "# we could also break up the process\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I used dictionary syntax to isolate the Phrase column. Now let's try using an alternative syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative syntax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above code, we can see that we have 101 cats from the UK in our dataset. We may want to calculate summary statistics for each cat. To group data and perform calculations, you will use the `.groupby()` method. Once you have grouped your data, there are additional methods you can use to explore that data like `.first()` which prints the first entry from each group or you can use the `.get_group()` method to access a specific group. In this example, we will group by the 'individual-local-identifier' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by individual-local-identifier\n",
    "\n",
    "\n",
    "# printing the first entry of each group\n",
    "\n",
    "\n",
    "# accessing the 'Abba' group\n",
    "# comment out line above to see output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to work with a grouped object, let's calculate some summary statisitcs on the ground-speed column. To do this, we can call the function we're interested in after our grouped data frame object. For example, if we want to caclulate the mean of frequency per group, it would look like this `grouped_cats.mean()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the mean fucntion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code when we called the `.mean()` function, it calculated the mean for not just the ground-speed column, but for all numeric columns. If we want to only see the mean of ground-speed per cat then we will need to subset the columns first. We did this earlier by using `[]` and we will use the same method here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting the grouped data frame to only include 'ground-speed'\n",
    "\n",
    "# calculate the mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could also chain everything together\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you try\n",
    "- Group by tag-local-identifier column\n",
    "- calculating the variance of the ground-speed per cat using the .var() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the data\n",
    "\n",
    "\n",
    "# subsetting the grouped data frame to only include 'ground-speed'\n",
    "\n",
    "\n",
    "# calculate the variance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering rows\n",
    "Not only can you subset columns, but you can also subset to specific rows. The first way we'll do this is by using logical statements. Let's start by only selecting data where the longitude is less than -5. We'll start by creating a logical statement that returns true for the years 1950 or later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the longitude is less than -5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a conditional statement, we can use that to filter to our rows of interest. To do that, we'll use the following syntax `dataframe[conditional_statment]`. This is illustrated below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the condional statement from above to filter the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter the dataframe to rows where ground-speed is greater than 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter cats_uk dataframe for rows where ground-speed is greater than 500\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to subset the dataframe based on whether values occured in a list, you can use `.isin()` method. For example, we may want to subset to specific values in the Phrase column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of Phrases of interest\n",
    "cat_name = ['Abba', 'Whiskey']\n",
    "\n",
    "# subset dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "Another great way to get familiar with your day is by visualizing it. We'll use the `matplotlib` package to create some basic plots of our data. This package is a common one in Python and works well with pandas. There are other plotting library options, depending on what you're trying to accomplish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statement\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've imported matplot lib, let's start by making a line chart of ground-speed for the Ares. To do this, we'll first subset the data to just Ares and then use the `plt.plot()` method to generate the line chart. After generating the chart, we will need to call `plt.show()` to actually view it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting data to ares\n",
    "\n",
    "\n",
    "# plotting time vs ground speed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this makes a plot, it's missing many elements. Let's try adding some additional features like axis labels to make it better. To do this, we'll use methods like `.title()` and `.xlabel()`. To learn more about the methods associated with plot objects from matplot lib you can review the documention here: https://matplotlib.org/stable/api/pyplot_summary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "# add axis labels\n",
    "\n",
    "# add title\n",
    "\n",
    "\n",
    "# add grid\n",
    "\n",
    "\n",
    "# create plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas dataframe objects have built-in functionality to use pyplot from matplotlib, so another way to call the `.plot()` method is directly after a pandas dataframe. If you do it that way, then you don't need to specify the dataframe when calling the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling .plot from the ares data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have focussed on create a chart with a single line representing the speed of one cat over time, but if we want a one charts with multiple lines representing the different cats in our dataset? To do this, we can use the `.groupby()` method we used above in combination with the `.plot()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to a few cats\n",
    "# create a list of Phrases of interest\n",
    "cat_name = ['Ares', 'Athena']\n",
    "\n",
    "# subset dataframe\n",
    "cats_uk_sub = cats_uk[cats_uk['individual-local-identifier'].isin(cat_name)]\n",
    "\n",
    "#define index column (necessary when using groupby)\n",
    "\n",
    "\n",
    "# groupby and plot\n",
    "\n",
    "# additional refinements\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Date')  #adding labels\n",
    "plt.ylabel('Ground speed (m/s)')\n",
    "plt.title(\"Ground speed of Ares and Athena over time\") #adding a title\n",
    "plt.grid()   # adding a grid to the background\n",
    "plt.tick_params(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Save figure once we're happy\n",
    "\n",
    "# if calling plt.show() it must come after plt.savefig\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only can you make line charts, but other types of charts as well. For example, we could make a bar plot of the average ground speed for each cat. To do this we will need to call `plot.bar()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first calculate the average ground speed for each cat\n",
    "cats_uk_avg = cats_uk.groupby('individual-local-identifier')['ground-speed'].mean()\n",
    "\n",
    "# let subet to the first 20 cats to make the chart more manageable\n",
    "cats_uk_avg = cats_uk_avg.iloc[0:20,]\n",
    "\n",
    "#calling .plot from the arts data frame\n",
    "cats_uk_avg.plot.bar('individual-local-identifier', 'ground-speed', \n",
    "          title = \"Average ground speed\", ylabel = \"Average ground speed (m/s)\", xlabel = \"Cat\", \n",
    "          grid = True) # specifying additional info from within\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra: Combining data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be times when you need to combine observations from multiple datasets. For example, we have been working with data from the UK, but there is also a dataset from the US. Let's combine these two datasets and create one dataframe. To do this, we will use the `.concat()` function from Pandas. To call that function, you must provide a list of objects to be combined. The call will look like this `pd.concat([list of objects])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case the file wasn't read in earlier\n",
    "# cats_us = pd.read_csv('data/Pet Cats United States.csv')\n",
    "\n",
    "# use the .concat() function\n",
    "\n",
    "# how many oberservations do we have in the new data set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may also be times when you want join additonal attributes to your dataset. For example, we have cat specific attributes in the Pet Cats United Kingdom-reference-data.csv file. Let's read that file in as well and then join the animal-life-stage column to our dataset, so we can investigate age in relation to our other attributes. To do this, we will use the `.merge()` method with the following syntax `dataframe.merge(other_dataframe)`. Although not required, it is also good practice to specify which column(s) you're performing the join on by using the `on` parameter and how you would like the join performed by using the `how` parameter.  More information on the merge function can be found here: https://pandas.pydata.org/docs/user_guide/merging.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Merge Types](HelpDocuments/merge_types.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in uk reference data\n",
    "\n",
    "\n",
    "# subset reference data to just animal-id and animal-life-stage\n",
    "\n",
    "\n",
    "# example of left join\n",
    "\n",
    "\n",
    "# view left join output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you try:\n",
    "- Filter the cats_us dataset to only rows where visible is true\n",
    "- Read in the Pet Cats United States-reference-data.csv and use a right merge to join it to the cats us_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter cats_-us to where visible is true\n",
    "\n",
    "\n",
    "# read in Pet Cats United States-reference-data.csv \n",
    "\n",
    "\n",
    "# right join to cats_us\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
